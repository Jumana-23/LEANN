{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start in 30s\n",
    "\n",
    "**Home GitHub Repository:** [LEANN on GitHub](https://github.com/yichuan-w/LEANN)\n",
    "\n",
    "**Important for Colab users:** Set your runtime type to T4 GPU for optimal performance. Go to Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí T4 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install this if you are using colab\n",
    "! uv pip install leann-core leann-backend-hnsw --no-deps\n",
    "! uv pip install leann --no-deps\n",
    "# For Colab environment, we need to set some environment variables\n",
    "import os\n",
    "\n",
    "os.environ[\"LEANN_LOG_LEVEL\"] = \"INFO\"  # Enable more detailed logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "INDEX_DIR = Path(\"./\").resolve()\n",
    "INDEX_PATH = str(INDEX_DIR / \"demo.leann\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing passages: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 17077.79chunk/s]\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 36.43it/s]\n",
      "WARNING:leann_backend_hnsw.hnsw_backend:Converting data to float32, shape: (5, 768)\n",
      "INFO:leann_backend_hnsw.hnsw_backend:INFO: Converting HNSW index to CSR-pruned format...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 64 for level: 0\n",
      "Starting conversion: index.index -> index.csr.tmp\n",
      "[0.00s] Reading Index HNSW header...\n",
      "[0.00s]   Header read: d=768, ntotal=5\n",
      "[0.00s] Reading HNSW struct vectors...\n",
      "  Reading vector (dtype=<class 'numpy.float64'>, fmt='d')... Count=6, Bytes=48\n",
      "[0.00s]   Read assign_probas (6)\n",
      "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=7, Bytes=28\n",
      "[0.14s]   Read cum_nneighbor_per_level (7)\n",
      "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=5, Bytes=20\n",
      "[0.24s]   Read levels (5)\n",
      "[0.33s]   Probing for compact storage flag...\n",
      "[0.33s]   Found compact flag: False\n",
      "[0.33s]   Compact flag is False, reading original format...\n",
      "[0.33s]   Probing for potential extra byte before non-compact offsets...\n",
      "[0.33s]   Found and consumed an unexpected 0x00 byte.\n",
      "  Reading vector (dtype=<class 'numpy.uint64'>, fmt='Q')... Count=6, Bytes=48\n",
      "[0.33s]   Read offsets (6)\n",
      "[0.41s]   Attempting to read neighbors vector...\n",
      "  Reading vector (dtype=<class 'numpy.int32'>, fmt='i')... Count=320, Bytes=1280\n",
      "[0.41s]   Read neighbors (320)\n",
      "[0.54s]   Read scalar params (ep=4, max_lvl=0)\n",
      "[0.54s] Checking for storage data...\n",
      "[0.54s]   Found storage fourcc: 49467849.\n",
      "[0.54s] Converting to CSR format...\n",
      "[0.54s]   Conversion loop finished.                        \n",
      "[0.54s] Running validation checks...\n",
      "    Checking total valid neighbor count...\n",
      "    OK: Total valid neighbors = 20\n",
      "    Checking final pointer indices...\n",
      "    OK: Final pointers match data size.\n",
      "[0.54s] Deleting original neighbors and offsets arrays...\n",
      "    CSR Stats: |data|=20, |level_ptr|=10\n",
      "[0.63s] Writing CSR HNSW graph data in FAISS-compatible order...\n",
      "   Pruning embeddings: Writing NULL storage marker.\n",
      "[0.71s] Conversion complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:leann_backend_hnsw.hnsw_backend:‚úÖ CSR conversion successful.\n",
      "INFO:leann_backend_hnsw.hnsw_backend:INFO: Replaced original index with CSR-pruned version at 'index.index'\n"
     ]
    }
   ],
   "source": [
    "from leann.api import LeannBuilder\n",
    "\n",
    "builder = LeannBuilder(backend_name=\"hnsw\")\n",
    "builder.add_text(\"C# is a powerful programming language and it is good at game development\")\n",
    "builder.add_text(\n",
    "    \"Python is a powerful programming language and it is good at machine learning tasks\"\n",
    ")\n",
    "builder.add_text(\"Machine learning transforms industries\")\n",
    "builder.add_text(\"Neural networks process complex data\")\n",
    "builder.add_text(\"Leann is a great storage saving engine for RAG on your MacBook\")\n",
    "builder.build_index(INDEX_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search with real-time embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:leann.api:üîç LeannSearcher.search() called:\n",
      "INFO:leann.api:  Query: 'programming languages'\n",
      "INFO:leann.api:  Top_k: 2\n",
      "INFO:leann.api:  Additional kwargs: {}\n",
      "INFO:leann.embedding_server_manager:Port 5557 has incompatible server, trying next port...\n",
      "INFO:leann.embedding_server_manager:Port 5558 has incompatible server, trying next port...\n",
      "INFO:leann.embedding_server_manager:Port 5559 has incompatible server, trying next port...\n",
      "INFO:leann.embedding_server_manager:Port 5560 has incompatible server, trying next port...\n",
      "INFO:leann.embedding_server_manager:Port 5561 has incompatible server, trying next port...\n",
      "INFO:leann.embedding_server_manager:Port 5562 has incompatible server, trying next port...\n",
      "INFO:leann.embedding_server_manager:Starting embedding server on port 5563...\n",
      "INFO:leann.embedding_server_manager:Command: /Users/yichuan/Desktop/code/test_leann_pip/LEANN/.venv/bin/python -m leann_backend_hnsw.hnsw_embedding_server --zmq-port 5563 --model-name facebook/contriever --passages-file /Users/yichuan/Desktop/code/test_leann_pip/LEANN/content/index.meta.json\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO:leann.embedding_server_manager:Server process started with PID: 31699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[read_HNSW - CSR NL v4] Reading metadata & CSR indices (manual offset)...\n",
      "[read_HNSW NL v4] Read levels vector, size: 5\n",
      "[read_HNSW NL v4] Reading Compact Storage format indices...\n",
      "[read_HNSW NL v4] Read compact_level_ptr, size: 10\n",
      "[read_HNSW NL v4] Read compact_node_offsets, size: 6\n",
      "[read_HNSW NL v4] Read entry_point: 4, max_level: 0\n",
      "[read_HNSW NL v4] Read storage fourcc: 0x6c6c756e\n",
      "[read_HNSW NL v4 FIX] Detected FileIOReader. Neighbors size field offset: 326\n",
      "[read_HNSW NL v4] Reading neighbors data into memory.\n",
      "[read_HNSW NL v4] Read neighbors data, size: 20\n",
      "[read_HNSW NL v4] Finished reading metadata and CSR indices.\n",
      "INFO: Skipping external storage loading, since is_recompute is true.\n",
      "INFO: Registering backend 'hnsw'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/yichuan/Desktop/code/test_leann_pip/LEANN/.venv/lib/python3.11/site-packages/leann_backend_hnsw/hnsw_embedding_server.py\", line 323, in <module>\n",
      "    create_hnsw_embedding_server(\n",
      "  File \"/Users/yichuan/Desktop/code/test_leann_pip/LEANN/.venv/lib/python3.11/site-packages/leann_backend_hnsw/hnsw_embedding_server.py\", line 98, in create_hnsw_embedding_server\n",
      "    passages = PassageManager(passage_sources)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yichuan/Desktop/code/test_leann_pip/LEANN/.venv/lib/python3.11/site-packages/leann/api.py\", line 127, in __init__\n",
      "    raise FileNotFoundError(f\"Passage index file not found: {index_file}\")\n",
      "FileNotFoundError: Passage index file not found: /Users/yichuan/Desktop/code/test_leann_pip/LEANN/index.passages.idx\n",
      "ERROR:leann.embedding_server_manager:Server terminated during startup.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to start embedding server on port 5563",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mleann\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LeannSearcher\n\u001b[32m      3\u001b[39m searcher = LeannSearcher(\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m results = \u001b[43msearcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprogramming languages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/code/test_leann_pip/LEANN/.venv/lib/python3.11/site-packages/leann/api.py:439\u001b[39m, in \u001b[36mLeannSearcher.search\u001b[39m\u001b[34m(self, query, top_k, complexity, beam_width, prune_ratio, recompute_embeddings, pruning_strategy, expected_zmq_port, **kwargs)\u001b[39m\n\u001b[32m    437\u001b[39m start_time = time.time()\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recompute_embeddings:\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m     zmq_port = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend_impl\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_ensure_server_running\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmeta_path_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_zmq_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m expected_zmq_port\n\u001b[32m    445\u001b[39m zmq_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/code/test_leann_pip/LEANN/.venv/lib/python3.11/site-packages/leann/searcher_base.py:81\u001b[39m, in \u001b[36mBaseSearcher._ensure_server_running\u001b[39m\u001b[34m(self, passages_source_file, port, **kwargs)\u001b[39m\n\u001b[32m     72\u001b[39m server_started, actual_port = \u001b[38;5;28mself\u001b[39m.embedding_server_manager.start_server(\n\u001b[32m     73\u001b[39m     port=port,\n\u001b[32m     74\u001b[39m     model_name=\u001b[38;5;28mself\u001b[39m.embedding_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     78\u001b[39m     enable_warmup=kwargs.get(\u001b[33m\"\u001b[39m\u001b[33menable_warmup\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m     79\u001b[39m )\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m server_started:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     82\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to start embedding server on port \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_port\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     83\u001b[39m     )\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m actual_port\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to start embedding server on port 5563"
     ]
    }
   ],
   "source": [
    "from leann.api import LeannSearcher\n",
    "\n",
    "searcher = LeannSearcher(INDEX_PATH)\n",
    "results = searcher.search(\"programming languages\", top_k=2)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat with LEANN using retrieved results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from leann.api import LeannChat\n",
    "\n",
    "llm_config = {\n",
    "    \"type\": \"hf\",\n",
    "    \"model\": \"Qwen/Qwen3-0.6B\",\n",
    "}\n",
    "\n",
    "chat = LeannChat(index_path=INDEX_PATH, llm_config=llm_config)\n",
    "response = chat.ask(\n",
    "    \"Compare the two retrieved programming languages and tell me their advantages.\",\n",
    "    top_k=2,\n",
    "    llm_kwargs={\"max_tokens\": 128},\n",
    ")\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
